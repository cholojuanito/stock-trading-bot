{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publicly available trading data for Representatives and Senators\n",
    "\n",
    "This data is made available because of the 2012 STOCK Act.\n",
    "\n",
    "## Data for each group can be found here:\n",
    "- Reps: https://disclosures-clerk.house.gov/FinancialDisclosure\n",
    "- Senators: https://efdsearch.senate.gov/search/home/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from the House of Representatives\n",
    "We'll start with data from the House of Representatives since they are the larger of the two groups and most of the people whose trading data we care about are Representatives.\n",
    "\n",
    "The data that the Clerk of the House provides are in the form of zip files. The data in this zip files serve as an index to all of the original pdfs that each member must submit.\n",
    "\n",
    "The zip files from the public disclosure website come in either text or xml format.\n",
    "Their schema is the following:\n",
    "- Prefix - the title of the person, nullable\n",
    "- Last - the Representative's last name\n",
    "- First - the Representative's first name\n",
    "- Suffix - the Representative's suffix, nullable\n",
    "- FilingType - one of C, D, P, W, X (more info below)\n",
    "- StateDst - the state and district the person is representing\n",
    "- Year - the year of the filing\n",
    "- FilingDate - the date of the filing\n",
    "- DocID - the internal id of the document, used for downloading the original pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A breakdown of the FilingTypes\n",
    "\n",
    "C - Candidacy Financial Disclosure Report:\n",
    "    Candidates are required to disclose their net worth and assets.\n",
    "    Example: https://disclosures-clerk.house.gov/public_disc/financial-pdfs/2024/10061382.pdf\n",
    "\n",
    "D - Financial Disclosure Report\n",
    "    Candidates are required to disclose if they have receieved more than $5,000 for their campaign.\n",
    "    Example: https://disclosures-clerk.house.gov/public_disc/financial-pdfs/2024/40003638.pdf\n",
    "\n",
    "P - Periodic Transaction Report\n",
    "    Candidates are required to disclose any transactions within 45 days of that transaction.\n",
    "    Example: https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2024/20025368.pdf\n",
    "\n",
    "W - Withdrawl of Candidacy\n",
    "    Example: https://disclosures-clerk.house.gov/public_disc/financial-pdfs/2024/7923.pdf\n",
    "\n",
    "X - Financial Disclosure Extension Request\n",
    "    Example: https://disclosures-clerk.house.gov/public_disc/financial-pdfs/2024/30022024.pdf\n",
    "\n",
    "**P FilingTypes are what we are most interested in, they provide the trade type,actual stock tickers, general amounts, and dates**\n",
    "\n",
    "### Where are the original pdfs stored?\n",
    "Each pdf is stored at URL that is a combination of the FilingType, Year, and DocID.\n",
    "\n",
    "Base URL for C, D, W, X: https://disclosures-clerk.house.gov/public_disc/financial-pdfs\n",
    "\n",
    "Base URL for P: https://disclosures-clerk.house.gov/public_disc/ptr-pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_disclosure_file(session: aiohttp.ClientSession, url: str, year: int, output_dir: Path):\n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                txt_file = f\"{year}FD.txt\"\n",
    "                content = await response.read()\n",
    "                with ZipFile(BytesIO(content)) as zip_file:\n",
    "                    if txt_file in zip_file.namelist():\n",
    "                        zip_file.extract(txt_file, output_dir)\n",
    "                        print(f\"Successfully downloaded and extracted {txt_file}\")\n",
    "                    else:\n",
    "                        print(f\"No {txt_file} found for {url}\")\n",
    "                return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "async def bulk_download_disclosure_files(base_url: str, years: range, output_dir: Path):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    files_to_download = []\n",
    "    for year in years:\n",
    "        txt_file = f\"{year}FD.txt\"\n",
    "        if (output_dir / txt_file).exists():\n",
    "            print(f\"File {txt_file} already exists, skipping download\")\n",
    "            continue\n",
    "        else:\n",
    "            files_to_download.append((year, txt_file))\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [download_disclosure_file(session, f\"{base_url}/{year}FD.zip\", year, output_dir) \n",
    "                for year, txt_file in files_to_download]\n",
    "        await asyncio.gather(*tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded and extracted 2010FD.txt\n",
      "Successfully downloaded and extracted 2008FD.txt\n",
      "Successfully downloaded and extracted 2009FD.txt\n",
      "Successfully downloaded and extracted 2024FD.txt\n",
      "Successfully downloaded and extracted 2011FD.txt\n",
      "Successfully downloaded and extracted 2012FD.txt\n",
      "Successfully downloaded and extracted 2013FD.txt\n",
      "Successfully downloaded and extracted 2021FD.txt\n",
      "Successfully downloaded and extracted 2022FD.txt\n",
      "Successfully downloaded and extracted 2023FD.txt\n",
      "Successfully downloaded and extracted 2017FD.txt\n",
      "Successfully downloaded and extracted 2016FD.txt\n",
      "Successfully downloaded and extracted 2015FD.txt\n",
      "Successfully downloaded and extracted 2014FD.txt\n",
      "Successfully downloaded and extracted 2018FD.txt\n",
      "Successfully downloaded and extracted 2019FD.txt\n",
      "Successfully downloaded and extracted 2020FD.txt\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://disclosures-clerk.house.gov/public_disc/financial-pdfs\"\n",
    "years = range(2008, 2025)\n",
    "output_dir = Path(\"../data/disclosures\")\n",
    "await bulk_download_disclosure_files(base_url, years, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_ptr_pdf(session, url: str, output_path: Path) -> bool:\n",
    "    \"\"\"Download a single PTR PDF file asynchronously.\"\"\"\n",
    "    try:\n",
    "        await asyncio.sleep(random.uniform(0.8, 1.3))  # Random delay between requests\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                content = await response.read()\n",
    "                with open(output_path, 'wb') as f:\n",
    "                    f.write(content)\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Failed to download {url}: Status {response.status}\")\n",
    "                return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def parse_filing_data(year: int) -> pd.DataFrame:\n",
    "    \"\"\"Parse the filing data file for a given year and return PTR records.\"\"\"\n",
    "    file_path = Path(f\"../data/disclosures/{year}FD.txt\")\n",
    "    \n",
    "    try:\n",
    "        # Read the tab-separated file\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "        \n",
    "        # Filter for PTR (Periodic Transaction Report) filings only\n",
    "        ptr_df = df[df['FilingType'] == 'P'].copy()\n",
    "        \n",
    "        # Convert FilingDate to datetime\n",
    "        ptr_df['FilingDate'] = pd.to_datetime(ptr_df['FilingDate'])\n",
    "        \n",
    "        return ptr_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def generate_pdf_filename(row) -> str:\n",
    "    \"\"\"Generate standardized filename for a PTR filing.\"\"\"\n",
    "    last_name = re.sub(r'[^a-zA-Z]', '', row['Last']).lower()\n",
    "    first_name = re.sub(r'[^a-zA-Z]', '', row['First']).lower()\n",
    "    state_dist = row['StateDst'].lower()\n",
    "    filing_date = row['FilingDate'].strftime('%Y-%m-%d')\n",
    "    \n",
    "    return f\"{last_name}_{first_name}_{state_dist}_{filing_date}.pdf\"\n",
    "\n",
    "async def process_batch(session, batch: list[tuple[str, str]], output_dir: Path) -> tuple[int, int]:\n",
    "    \"\"\"Process a batch of PTR downloads.\"\"\"\n",
    "    tasks = [download_ptr_pdf(session, url, output_dir / filename) \n",
    "             for url, filename in batch\n",
    "             if not (output_dir / filename).exists()]\n",
    "    \n",
    "    if tasks:\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return sum(1 for r in results if r), len(tasks)\n",
    "    return 0, 0\n",
    "\n",
    "async def download_ptr_pdfs(start_year: int, end_year: int, batch_size: int = 25):\n",
    "    \"\"\"\n",
    "    Download all PTR PDFs for the specified year range.\n",
    "\n",
    "    Args:\n",
    "        start_year (int): The start year of the range.\n",
    "        end_year (int): The end year of the range (inclusive).\n",
    "        batch_size (int): The number of PTRs to download concurrently.\n",
    "    \"\"\"\n",
    "    base_url = \"https://disclosures-clerk.house.gov/public_disc/ptr-pdfs\"\n",
    "    output_dir = Path(\"../data/ptrs\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            print(f\"Processing year {year}\")\n",
    "            \n",
    "            ptr_df = parse_filing_data(year)\n",
    "            if ptr_df.empty:\n",
    "                continue\n",
    "            \n",
    "            # Create list of all downloads needed\n",
    "            downloads = [\n",
    "                (f\"{base_url}/{year}/{row['DocID']}.pdf\", generate_pdf_filename(row))\n",
    "                for row in ptr_df.to_dict('records')\n",
    "            ]\n",
    "            \n",
    "            # Process in batches\n",
    "            total_successful = 0\n",
    "            total_attempts = 0\n",
    "            \n",
    "            for i in range(0, len(downloads), batch_size):\n",
    "                batch = downloads[i:i + batch_size]\n",
    "                successful, attempts = await process_batch(session, batch, output_dir)\n",
    "                total_successful += successful\n",
    "                total_attempts += attempts\n",
    "                \n",
    "            if total_attempts > 0:\n",
    "                print(f\"Year {year}: Downloaded {total_successful}/{total_attempts} PTR PDFs\")\n",
    "\n",
    "async def download_ptrs(start_year: int, end_year: int, batch_size: int = 25):\n",
    "    \"\"\"Main function to initiate PTR downloads.\"\"\"\n",
    "    await download_ptr_pdfs(start_year, end_year, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2014\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m download_ptrs(\u001b[38;5;241m2014\u001b[39m, \u001b[38;5;241m2024\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 100\u001b[0m, in \u001b[0;36mdownload_ptrs\u001b[0;34m(start_year, end_year, batch_size)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_ptrs\u001b[39m(start_year: \u001b[38;5;28mint\u001b[39m, end_year: \u001b[38;5;28mint\u001b[39m, batch_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m):\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Main function to initiate PTR downloads.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m download_ptr_pdfs(start_year, end_year, batch_size)\n",
      "Cell \u001b[0;32mIn[16], line 91\u001b[0m, in \u001b[0;36mdownload_ptr_pdfs\u001b[0;34m(start_year, end_year, batch_size)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(downloads), batch_size):\n\u001b[1;32m     90\u001b[0m     batch \u001b[38;5;241m=\u001b[39m downloads[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m---> 91\u001b[0m     successful, attempts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m process_batch(session, batch, output_dir)\n\u001b[1;32m     92\u001b[0m     total_successful \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m successful\n\u001b[1;32m     93\u001b[0m     total_attempts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m attempts\n",
      "Cell \u001b[0;32mIn[16], line 54\u001b[0m, in \u001b[0;36mprocess_batch\u001b[0;34m(session, batch, output_dir)\u001b[0m\n\u001b[1;32m     49\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [download_ptr_pdf(session, url, output_dir \u001b[38;5;241m/\u001b[39m filename) \n\u001b[1;32m     50\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m url, filename \u001b[38;5;129;01min\u001b[39;00m batch\n\u001b[1;32m     51\u001b[0m          \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (output_dir \u001b[38;5;241m/\u001b[39m filename)\u001b[38;5;241m.\u001b[39mexists()]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tasks:\n\u001b[0;32m---> 54\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m r), \u001b[38;5;28mlen\u001b[39m(tasks)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m, in \u001b[0;36mdownload_ptr_pdf\u001b[0;34m(session, url, output_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download a single PTR PDF file asynchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.3\u001b[39m))  \u001b[38;5;66;03m# Random delay between requests\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mget(url) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/asyncio/tasks.py:665\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    661\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[1;32m    662\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[1;32m    663\u001b[0m                     future, result)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    667\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "await download_ptrs(2014, 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
